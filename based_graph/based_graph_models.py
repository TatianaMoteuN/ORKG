# -*- coding: utf-8 -*-
"""based_graph_models.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1nqaWDRc0sCW-6j50n3dADl8WfWaO2Svw
"""

####  If you encounter a problem while importing ampligraph, make sure you have installed it
#import librairies
import os
import pandas as pd
import numpy as np
import ampligraph
from ampligraph.latent_features import ComplEx, TransE, DistMult, HolE



#we define possibles models that will be used for the knowledge based graph
def complex():
  model = ComplEx(k=150,                                                             # embedding size
                epochs=300,                                                        # Num of epochs
                batches_count= 10,                                                 # Number of batches 
                eta=10,                                                             # number of corruptions to generate during training
                loss='pairwise', loss_params={'margin': 1},                        # loss type and it's hyperparameters         
                initializer='xavier', initializer_params={'uniform': False},       # initializer type and it's hyperparameters
                regularizer='LP', regularizer_params= {'lambda': 0.001, 'p': 3},   # regularizer along with its hyperparameters
                optimizer= 'adam', optimizer_params= {'lr': 0.0001},                # optimizer to use along with its hyperparameters
                seed= 0, verbose=True)
  return model


def transe():
  model = TransE(k=150,                                                             # embedding size
                epochs=300,                                                        # Num of epochs
                batches_count= 10,                                                 # Number of batches 
                eta=10,                                                             # number of corruptions to generate during training
                loss='pairwise', loss_params={'margin': 1},                        # loss type and it's hyperparameters         
                initializer='xavier', initializer_params={'uniform': False},       # initializer type and it's hyperparameters
                regularizer='LP', regularizer_params= {'lambda': 0.001, 'p': 3},   # regularizer along with its hyperparameters
                optimizer= 'adam', optimizer_params= {'lr': 0.0001},                # optimizer to use along with its hyperparameters
                seed= 0, verbose=True)
  return model

def distmult():
  model = DistMult(k=150,                                                             # embedding size
                epochs=300,                                                        # Num of epochs
                batches_count= 10,                                                 # Number of batches 
                eta=10,                                                             # number of corruptions to generate during training
                loss='pairwise', loss_params={'margin': 1},                        # loss type and it's hyperparameters         
                initializer='xavier', initializer_params={'uniform': False},       # initializer type and it's hyperparameters
                regularizer='LP', regularizer_params= {'lambda': 0.001, 'p': 3},   # regularizer along with its hyperparameters
                optimizer= 'adam', optimizer_params= {'lr': 0.0001},                # optimizer to use along with its hyperparameters
                seed= 0, verbose=True)
  return model


def hole():
  model = HolE(k=150,                                                             # embedding size
                epochs=300,                                                        # Num of epochs
                batches_count= 10,                                                 # Number of batches 
                eta=10,                                                             # number of corruptions to generate during training
                loss='pairwise', loss_params={'margin': 1},                        # loss type and it's hyperparameters         
                initializer='xavier', initializer_params={'uniform': False},       # initializer type and it's hyperparameters
                regularizer='LP', regularizer_params= {'lambda': 0.001, 'p': 3},   # regularizer along with its hyperparameters
                optimizer= 'adam', optimizer_params= {'lr': 0.0001},                # optimizer to use along with its hyperparameters
                seed= 0, verbose=True)
  return model